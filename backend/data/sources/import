#! /usr/bin/perl

use Text::CSV qw( csv );
use List::Util qw( any none uniq );
use JSON::XS;
use Array::Utils qw(:all);
use Data::Dumper;
use File::Copy qw(copy);
use Cwd qw(getcwd);
use File::Basename;


my $file         = shift; # Absolute path
my $cache        = cache( $file );
my $path         = path( $file );
my $pdir = dirname($path);
my @required     = qw( mention1 mention2 geneids1 geneids2 type1 type2 probability );
my @optional     = ();#qw( journal article_id pubmed_id sentence_id mention1_offset mention2_offset probability context section);
my @add_col = null;
my $interactions = csv( in => validate( $file ), encoding => 'utf-8');
$interactions = csv( in => $file, encoding => 'utf-8', headers => "auto");

# ===== CLEANUP
cleanup( $interactions );

# ===== GENERATE ADJACENCY MATRIX
print "<ul><li>Building <i>adjacency matrix</i></li>\n";
adjacency_matrix( $cache, $interactions );#changed $cache to $path NL

# ===== GENERATE TYPEAHEAD LOOKUP CACHES
foreach my $type (qw( gene drug disease )) {
	my $hash = {};
	extract_ids( $type, $hash, $_ ) foreach @$interactions;
	hash_to_cache( $type, $cache, $hash );#changed $cache to $path NL
  	print "<li>Building <i>$type typeahead lookup cache</li>\n";
}

filter_columns( $interactions );
print "</ul>Preparing to load data into the database<br>\n";
write_sql( $path, $interactions );
$parent = basename(dirname($file));
$parent = "ds_".$parent;
$location = $path."/template.js";

copy("$pdir/template.js",$location) or die "copy failed : $!";
#add file with specific datasource in class name
#rename the class name in the datasource
string_replace($location,"LocalTable",$parent);

$replace_string = join(",",map " \"$_\"",@add_col);
#print($replace_string);
string_replace($location,"this.add_cols = null","this.add_cols = [". $replace_string."]");

# ==== PLUGIN ARCHITECTURE
print($parent);
copy($location,"/genedive/frontend/datasource/view/table/plugin/sources/".$parent.".js") or die "copy failed : $!";


# ============================================================
sub adjacency_matrix {
# ============================================================
	my $cache        = shift;
	my $interactions = shift;

	my $matrix = {};

	foreach my $interaction (@$interactions) {
		my $a    = $interaction->{ geneids1 };
		my $b    = $interaction->{ geneids2 };
		my $p    = $interaction->{ probability };

		$matrix->{ $a }{ $b } = [] if not exists $matrix->{ $a }{ $b };
		$matrix->{ $a }{ $b } = [ sort { $a <=> $b } (($p*1000), @{ $matrix->{ $a }{ $b }})];
		$matrix->{ $b }{ $a } = $matrix->{ $a }{ $b }; # Enforce bidirectionality
	}

	my $json = new JSON::XS();
  	unless( -d $cache ) { mkdir $cache; chmod 0777, $cache; }
	open FILE, ">$cache/adjacency_matrix.js" or die "Can't write to '$cache/adjacency_matrix.js' $!";
	print FILE "var adjacency_matrix = ";
	print FILE $json->canonical->encode( $matrix );
	print FILE ";";
	close FILE;
}

# ============================================================
sub cache {
# ============================================================
	my $file  = shift;
	my @paths = split /\//, $file; pop @paths;
	my $cache = '/var/www/html/cache/' . pop @paths;

	return $cache;
}

# ============================================================
sub cleanup {
# ============================================================
	my $interactions = shift;
	foreach my $i (@$interactions) {
    $i->{ type1 } = lc $i->{ type1 };
    $i->{ type2 } = lc $i->{ type2 };
		if( exists $i->{ id1 }) { $i->{ geneids1 } = $i->{ id1 }; delete $i->{ id1 }; }
		if( exists $i->{ id2 }) { $i->{ geneids2 } = $i->{ id2 }; delete $i->{ id2 }; }
		if( ! exists $i->{ probability }) { $i->{ probability } = 0.7; }
	}
}

# ============================================================
sub double_quote {
# ============================================================
	my $value = shift;
	$value =~ s/"/""/g;
	return "\"$value\"";
}

# ============================================================
sub filter_columns {
# ============================================================
	my $interactions = shift;
	my $denied = [ grep { my $field = $_; none { $field eq $_ } (@required, @optional) } keys %{$interactions->[ 0 ]}];
	foreach my $interaction (@$interactions) {
		delete $interaction->{ $_ } foreach @$denied;
	}
}

# ============================================================
sub extract_ids {
# ============================================================
	my $type    = shift;
	my $hash    = shift;
	my $entry   = shift;

	foreach my $i ( 1, 2 ) {
		next unless( $entry->{ "type$i" } eq $type );
		my $id     = $entry->{ "geneids$i" };
		my $symbol = $entry->{ "mention$i" };
		push @{$hash->{ $symbol }}, $id;
	}
}

# ============================================================
sub hash_to_cache {
# ============================================================
	my $type  = shift;
	my $cache = shift;
	my $hash  = shift;
	my $json  = new JSON::XS();

	my $data = [];
	foreach my $key (sort { $a cmp $b } keys %$hash) {
		push @$data, { symbol => $key, values => [ uniq @{$hash->{ $key }} ]};
	}

  	unless( -d $cache ) { mkdir $cache; chmod 0777, $cache; }
	open FILE, ">$cache/$type" . '_id.js' or die $!;
	printf FILE "var AUTOCOMPLETE_%s = ", uc( $type );
	print FILE $json->canonical->encode( $data );
	print FILE ";";
	close FILE;
}

# ============================================================
sub insert_table {
# ============================================================
return <<EOF;
CREATE TABLE IF NOT EXISTS interactions (
	id INTEGER NOT NULL, 
	journal TEXT, 
	article_id TEXT, 
	pubmed_id TEXT, 
	sentence_id TEXT, 
	mention1_offset INTEGER, 
	mention2_offset INTEGER, 
	mention1 TEXT collate nocase, 
	mention2 TEXT collate nocase, 
	geneids1 TEXT, 
	geneids2 TEXT, 
	probability FLOAT, 
	context TEXT, 
    	section TEXT, 
	type1 CHARACTER(1), 
	type2 CHARACTER(1),
	addendum TEXT,
	PRIMARY KEY (id)
);
CREATE INDEX IF NOT EXISTS gid1 on interactions(geneids1);
CREATE INDEX IF NOT EXISTS gid2 on interactions(geneids2);
EOF
}

# ============================================================
sub path {
# ============================================================
	my $file  = shift;
	my @paths = split /\//, $file; pop @paths;
	my $path  = join( '/', @paths ) || '.';

	return $path;
}

# ============================================================
sub validate {
# ============================================================
	my $file     = shift;

	open FILE, $file or die $!;
	my $header = <FILE>;
	$header =~ s/\s*$//;
	close FILE;
	my @headers = split /,\s*/, $header;
	my $alias = { geneids1 => 'id1', geneids2 => 'id2' };

	# ===== ENFORCE REQUIRED FIELDS
	foreach my $required (@required) {
		my $aliases = exists $alias->{ $required } ? [ $alias->{ $required } ] : [];
		unless( grep { 
			my $field = $_;
			$field eq $required || any { $field eq $_ } @{$aliases}
		} @headers ) {
			printf( "{\"result\":\"error\",\"line\":1,\"description\":\"Missing required field '%s'\"}\n", $required );
			exit( 1 );
		}
	}
	#get additional columns
	@add_col = array_minus(@headers, @required);#my removed NL
	@add_col = array_minus( @add_col, @optional);
	if (!@add_col){
	  return $file;
	}
	push @optional, "addendum";
	my $pos =0;
	my %col2_num = map {$_ => $pos++}@headers;
	my @slice = map{$col2_num{$_}}@add_col;
	#convert additional columns to json format
	my $json = new JSON::XS();
	my @new_col;
	#open( FILE, $file ) or die "Cannot open '$file'\n";
	my $headerFlag = 1;

	#mapping the addendum column
	my $csv = Text::CSV->new ({ binary => 1 });
	open my $fh, "<", $file or die "$file: $!";
	my $i = 1;
	my @rows;
	while (my $row = $csv->getline ($fh)) {
	my $col_num = 0;
	if($i == 1){
		push @$row,"addendum";	

	}else{
		for($index = 0; $index <= $#headers; $index++)
		{
			if ($index == @slice[$col_num]){
				$map{"$headers[$index]"} = @$row[$index];
				$col_num++;
			}
		}
		
		push @$row,$json->canonical->encode(\%map);
	}
	push(@rows,[@$row]);
	$i++;
	}
	close $fh;
	#update file with the new column
	open ($fh,">",$file) or die $! ;
	$csv->say ($fh, $_) for @rows;		
	close ($fh);
	#return the file
	return $file;
}

# ============================================================
sub write_sql {
# ============================================================
	my $path         = shift;
	my $interactions = shift;

	my $file = "$path/data.import.sql";
	my $last = $#$interactions;
	open (FILE, '>:encoding(UTF-8)', $file) or die $!;
	print FILE insert_table();
	my $group = 1000; # Max number of rows for INSERT for SQLite3
	my @columns = map { exists $alias->{ $_ } ? $alias->{ $_ } : $_ } (@required, @optional);
	foreach my $i ( 0 .. $last ) {
		my $end_of_data    = ($i == $last);
		my $start_of_group = (($i % $group) == 0);
		my $end_of_group   = ($i % $group == ($group - 1));
		if( $start_of_group ) { 
			printf FILE "insert into interactions (%s) values\n", join( ', ', @columns );
		};
		my $interaction = $interactions->[ $i ];
		my @values = ();
		foreach my $key (@columns) {
			my $exists  = exists $interaction->{ $key };
			my $numeric = qr/^(probability|mention1_offset|mention2_offset)$/;
			if( $key =~ $numeric ) {
				if( $exists ) { push @values, $interaction->{ $key }; }
				else          { push @values, 'NULL'; }
			} else {
				if( $exists ) { push @values, double_quote( $interaction->{ $key } ); }
				else          { push @values, double_quote(''); }
			}
		}
		printf FILE "( %s )%s", join( ', ', @values ), ( $end_of_group || $end_of_data ? ";\n\n" : ",\n" );
		
	}
	close FILE;
}

# ============================================================
sub string_replace{
# ============================================================
  my($file,$pattern,$replacement) = @_;
  #open the file to read
  open my $fh ,"<", $file or die "Unable to read from $file $? $!";
  my @lines = <$fh>;
  close $fh;
  # foreach(@lines){
  #$_ =~ s/$pattern/$replacement/g;
# }
  #replace and write to file 
  open my $fh ,">", $file or die "Unable to write to $file $? $!";
    for(@lines){
    $_ =~ s/$pattern/$replacement/g;
    print {$fh} $_;
    }
  close $fh;
}
