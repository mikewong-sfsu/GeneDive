{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract-Transform-Load Script\n",
    "\n",
    "Extract-Transform-Load Scripts (ETLS) are common tools in data management. The purpose of ETLS is to gather relevant data (both direct and inferred) from public databases and capture important features in a possibly different data structure schema for specific analysis.\n",
    "\n",
    "## PubMed Central ETLS Example\n",
    "\n",
    "This script will Extract data from the CSV files provided to us by Stanford, Transform the data into a format usable by GeneDive, and then Load the data into the GeneDive sqlite database.\n",
    "\n",
    "Whenever new data is obtained for GeneDive, this process should be run against that dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress Bar I found on the internet.\n",
    "# https://github.com/alexanderkuk/log-progress\n",
    "from progress_bar import log_progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">IMPORTANT!</span> You need to create folders and organize the data before starting\n",
    "\n",
    "Below are many file names and directory names. You have to create the directories and put the files correctly in them.\n",
    "\n",
    "`GENE_GENE_INTERACTIONS_FILE`, `GENE_DRUG_INTERACTIONS_FILE`, and `GENE_DISEASE_INTERACTIONS_FILE` are TSV files from Emily. If they come with a .csv extension, and they are tab seperated, rename them. If they are deliminated some other way, change their extensions appropriately and change the value of `DELIMITER` below.\n",
    "\n",
    "`GOOD_PHARM_GKB_DB`, `GOOD_ALL_DB`, and `GOOD_PLOS_PMC_DB` are the current working, valid databases used in GeneDive. They will not be altered, but instead they will be copied and updated.\n",
    "\n",
    "`PLOS_PMC_DB` and `ALL_DB` are the newly generated databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSV files containing Emily's data\n",
    "GENE_GENE_INTERACTIONS_FILE    = 'tsv_data/genegene_relationship_db_sfsu.tsv'\n",
    "GENE_DRUG_INTERACTIONS_FILE    = 'tsv_data/genedrug_relationship_100417_sfsu_with_excerpts.tsv'\n",
    "GENE_DISEASE_INTERACTIONS_FILE = 'tsv_data/genedisease_relationship_100417_sfsu_with_excerpts.tsv'\n",
    "\n",
    "# These will be unaltered\n",
    "GOOD_PHARM_GKB_DB = 'sqlite_data/good_data/data.pgkb.sqlite'\n",
    "GOOD_ALL_DB = 'sqlite_data/good_data/data.all.sqlite'\n",
    "GOOD_PLOS_PMC_DB = 'sqlite_data/good_data/data.plos-pmc.sqlite'\n",
    "\n",
    "# These will be created/overwritten\n",
    "PLOS_PMC_DB = 'sqlite_data/data.plos-pmc.sqlite' # This will be just the data from emilies files\n",
    "ALL_DB = 'sqlite_data/data.all.sqlite' # This is a combination of emilies files and PharmGKB\n",
    "\n",
    "# if excepts alrady come wrapped with pound signs, set this to false\n",
    "WRAP_EXCERPTS = False\n",
    "\n",
    "DELIMITER = \"\\t\"\n",
    "EMILYS_FILES = [\n",
    "    #{\"filename\":GENE_GENE_INTERACTIONS_FILE,\"type\":\"GeneGene\"}, # we're not importing because the genegene interactions contain no excerpts, which would overwrite the good data\n",
    "    {\"filename\":GENE_DRUG_INTERACTIONS_FILE,\"type\":\"GeneDrug\"},\n",
    "    {\"filename\":GENE_DISEASE_INTERACTIONS_FILE,\"type\":\"GeneDisease\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If write is false, the script will run but not write anything to the database. This keeps it safe while you're nosing around, and can also be useful if you need to re-generate the complete typeahead/adjacency files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This copies the fields, then initializes the connections. The `databases` array will be looped through at the end, applying all the interactions to each database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2(GOOD_PLOS_PMC_DB, PLOS_PMC_DB)\n",
    "conn_plos_pmc = sqlite3.connect(PLOS_PMC_DB)\n",
    "cursor_plos_pmc = conn_plos_pmc.cursor()\n",
    "\n",
    "copy2(GOOD_ALL_DB, ALL_DB)\n",
    "conn_all = sqlite3.connect(ALL_DB)\n",
    "cursor_all = conn_all.cursor()\n",
    "\n",
    "\n",
    "databases = [\n",
    "    {\"conn\": conn_plos_pmc, \"cursor\": cursor_plos_pmc, \"name\": \"PLOS-PMC\"}, \n",
    "    {\"conn\": conn_all, \"cursor\": cursor_all, \"name\": \"ALL\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the columns as they appear in the file to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the exercept is not found, don't run the Excerpt wrapping cell below\n",
    "excerptFound = False\n",
    "interactions = []\n",
    "for data_file in EMILYS_FILES:\n",
    "    \n",
    "    # Prepending to identify each DGD so that they can be identified as a Gene (no-prepend), Drug (C), or Disease (D)\n",
    "    prePendDGDID1 = \"\"\n",
    "    prePendDGDID2 = \"\"\n",
    "    if data_file[\"type\"] == \"GeneDrug\":\n",
    "        prePendDGDID1 = \"C\"\n",
    "    elif data_file[\"type\"] == \"GeneDisease\":\n",
    "        prePendDGDID1 = \"D\"\n",
    "    elif data_file[\"type\"] == \"GeneGene\":\n",
    "        1# do nothing\n",
    "    else:\n",
    "        raise ValueError('{type} is an unrecognized type in EMILYS_FILES'.format(type = data_file[\"type\"]))\n",
    "        \n",
    "    with open(data_file[\"filename\"]) as file:\n",
    "        header = None\n",
    "        linenum = 0  \n",
    "        for line in file:\n",
    "            linenum+=1\n",
    "            \n",
    "            # Read the headers of the file and assign them to a dictionary {column_name: column_number}\n",
    "            if linenum == 1:\n",
    "                header = {name.strip(): col for col, name in enumerate(line.split(DELIMITER))}\n",
    "                \n",
    "                # The GeneGene headers differ from Gene Drug and Gene Disease. This normalizes them.\n",
    "                if \"geneids\" in header and \"disease_ids\" in header: # GeneDrug/GeneDisease\n",
    "                    header[\"dgd1\"] = header[\"geneids\"]\n",
    "                    header[\"dgd2\"] = header[\"disease_ids\"]                    \n",
    "                    header[\"mention1_offset\"] = header[\"mention1_offset_start\"]\n",
    "                    header[\"mention2_offset\"] = header[\"mention2_offset_start\"]\n",
    "                elif \"geneids1\" in header and \"geneids2\" in header: # GeneGene\n",
    "                    header[\"dgd1\"] = header[\"geneids1\"]\n",
    "                    header[\"dgd2\"] = header[\"geneids2\"]\n",
    "                else:\n",
    "                    raise ValueError('{f} column headers didn\\'t contain expected values'.format(f = data_file[\"filename\"]))\n",
    "                \n",
    "                # if no excerpts provided, substituted with article name        \n",
    "                if \"excerpt\" in header:                    \n",
    "                    excerptFound = True\n",
    "                else:\n",
    "                    header[\"excerpt\"] = header[\"article_id\"]\n",
    "                \n",
    "                #print(header)\n",
    "                    \n",
    "                continue\n",
    "                \n",
    "            line = line.strip().split(DELIMITER)\n",
    "\n",
    "            interaction = {\n",
    "              \"journal\": line[header[\"journal\"]], # no change\n",
    "              \"article_id\": line[header[\"article_id\"]], # no change\n",
    "              \"pubmed_id\": line[header[\"pubmed_id\"]], # no change\n",
    "              \"sentence_id\": line[header[\"sentence_id\"]], # no change\n",
    "              \"mention1_offset\": line[header[\"mention1_offset\"]], # new data describes a mention1_offset_start and mention1_offset_end -- I arbitarily chose to just assign offset_start here (offset start and end are often the same anyway) \n",
    "              \"mention2_offset\": line[header[\"mention2_offset\"]], # same principle as above, but for mention2\n",
    "              \"mention1\": line[header[\"mention1\"]], # no change\n",
    "              \"mention2\": line[header[\"mention2\"]], # no change\n",
    "              \"geneids1\": prePendDGDID1+ line[header[\"dgd1\"]], # there's a column named \"geneids\", but it never seems to contain more than one value \"MESH:xxxxxxx\"\n",
    "              \"geneids2\": prePendDGDID2+line[header[\"dgd2\"]], # the column after \"geneids\" is called \"disease_ids\", and may be a suitable substitute for this geneids value\n",
    "              \"probability\": line[header[\"probability\"]], # no change\n",
    "              \"excerpt\": line[header[\"excerpt\"]] \n",
    "            }\n",
    "\n",
    "            interactions.append(interaction)\n",
    "totalInteractions = len(interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any interactions for which the a gene traces to multiple IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Interactions:     584939\n",
      "Filtered Interactions:  60903\n",
      "Remaining Interactions: 524036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interactions = [i for i in interactions if ( \n",
    "        ';' not in i['geneids1'] \n",
    "    and ';' not in i['geneids2'])]\n",
    "interactions = [i for i in interactions if (\n",
    "        'NULL' not in i['article_id'] \n",
    "    and 'NULL' not in i['pubmed_id'] \n",
    "    and 'NULL' not in i['sentence_id'] \n",
    "    and 'NULL' not in i['mention1_offset'] \n",
    "    and 'NULL' not in i['mention2_offset'] \n",
    "    and 'NULL' not in i['mention1'] \n",
    "    and 'NULL' not in i['mention2'] \n",
    "    and 'NULL' not in i['geneids1'] \n",
    "    and 'NULL' not in i['geneids2'] \n",
    "    and 'NULL' not in i['probability'] \n",
    "    and 'NULL' not in i['excerpt'])] #there's probably a shorter way of doing this, but I think this works for now -- excludes JOURNAL entries of course\n",
    "\n",
    "\n",
    "newTotal = len(interactions)\n",
    "print(\n",
    "'''Total Interactions:     {total}\n",
    "Filtered Interactions:  {filtered}\n",
    "Remaining Interactions: {remaining}'''\n",
    "      .format(total = totalInteractions,filtered=totalInteractions-newTotal , remaining =newTotal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excerpt wrapping\n",
    "GeneDive expects the target genes in the excerpt to be wrapped in pound signs. This is important because a sentence may mention the target gene multiple times, so we need to use the offset data her to make sure we tag the right mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if excerptFound and WRAP_EXCERPTS:\n",
    "    for i in interactions:\n",
    "        #try:\n",
    "        print(i)\n",
    "        if (i['journal'] != 'journal' and 'excerpt' in i):\n",
    "            excerpt = i['excerpt']\n",
    "\n",
    "            excerpt = re.sub('\"', '', excerpt)\n",
    "            tokens = excerpt.split(\" \")\n",
    "            offset1 = int(i['mention1_offset'])\n",
    "            offset2 = int(i['mention2_offset'])\n",
    "\n",
    "            tokens[offset1] = \"\".join([\"#\",tokens[offset1],\"#\"])\n",
    "            tokens[offset2] = \"\".join([\"#\",tokens[offset2],\"#\"])\n",
    "\n",
    "            i['excerpt'] = \" \".join(tokens)\n",
    "        #except Exception:\n",
    "        #    print(i[\"article_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specific for PMC Data**\n",
    "\n",
    "We didn't get Journal Data - we need to extract it from the article titles. Comment out the next section if journal titles were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in interactions:\n",
    "    journal_split = i['article_id'].split(\"_\")\n",
    "    x = 0\n",
    "    length = len(journal_split)\n",
    "    journal = \"\"\n",
    "    \n",
    "    while x < length:\n",
    "        if journal_split[x][:2] == \"19\" or journal_split[x][:2] == \"20\" or x == length -1:\n",
    "            journal = \" \".join(journal_split[:x])\n",
    "            break\n",
    "        x+= 1\n",
    "    \n",
    "    break\n",
    "\n",
    "    i['journal'] = journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our insert statement - probably don't need to touch this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIONS_WRITE = '''insert into interactions ( journal, article_id, pubmed_id, sentence_id, mention1_offset, mention2_offset, mention1, mention2, geneids1, geneids2, probability, context, section, reactome ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? );'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the data to sqlite files\n",
    "\n",
    "This will load the data into the plos-pmc database and the all database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cce650b391e4243bfd6517448c4c307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=524036)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf4c4f27ef64875bd7690c3e2859bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=524036)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All databases complete\n"
     ]
    }
   ],
   "source": [
    "for sql in databases:\n",
    "    try:\n",
    "        for interaction in log_progress(interactions, every=1000, name=sql[\"name\"]+\" database progress\"):\n",
    "            statement = (\n",
    "                interaction['journal'],\n",
    "                interaction['article_id'],\n",
    "                interaction['pubmed_id'],\n",
    "                interaction['sentence_id'],\n",
    "                interaction['mention1_offset'],\n",
    "                interaction['mention2_offset'],\n",
    "                interaction['mention1'],\n",
    "                interaction['mention2'],\n",
    "                interaction['geneids1'],\n",
    "                interaction['geneids2'],\n",
    "                interaction['probability'],\n",
    "                interaction['excerpt'],\n",
    "                \"Unknown\",\n",
    "                0\n",
    "            )\n",
    "\n",
    "            sql[\"cursor\"].execute(INTERACTIONS_WRITE,statement)\n",
    "\n",
    "        if WRITE:\n",
    "            sql[\"conn\"].commit()\n",
    "    except Exception as e:\n",
    "        print(INTERACTIONS_WRITE, statement)\n",
    "        raise e\n",
    "\n",
    "    sql[\"conn\"].close()\n",
    "\n",
    "print(\"All databases complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
