{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract-Transform-Load Script\n",
    "\n",
    "Extract-Transform-Load Scripts (ETLS) are common tools in data management. The purpose of ETLS is to gather relevant data (both direct and inferred) from public databases and capture important features in a possibly different data structure schema for specific analysis.\n",
    "\n",
    "## PubMed Central ETLS Example\n",
    "\n",
    "This script will Extract data from the CSV files provided to us by Stanford, Transform the data into a format usable by GeneDive, and then Load the data into the GeneDive sqlite database.\n",
    "\n",
    "Whenever new data is obtained for GeneDive, this process should be run against that dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIONS_FILE = \"genedisease_relationship_100417_sfsu.csv\"\n",
    "DELIMITER = \"\\t\"\n",
    "DATABASE = \"data.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If write is false, the script will run but not write anything to the database. This keeps it safe while you're nosing around, and can also be useful if you need to re-generate the complete typeahead/adjacency files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DATABASE)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the columns as they appear in the file to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'journal': 'NULL', 'article_id': 'Mol_Cancer_2009_Aug_25_8_66.nxml.txt.nlp', 'pubmed_id': '19706164', 'sentence_id': 'SENT5', 'mention1_offset': '17', 'mention2_offset': '3', 'mention1': 'glioblastoma', 'mention2': 'p53', 'geneids1': 'MESH:D005909', 'geneids2': '7157', 'probability': '0.999', 'excerpt': 'Mol_Cancer_2009_Aug_25_8_66.nxml.txt.nlp'}\n"
     ]
    }
   ],
   "source": [
    "interactions = []\n",
    "\n",
    "with open(INTERACTIONS_FILE) as file:\n",
    "    for line in file:\n",
    "        line = line[:-1]\n",
    "        line = line.split(DELIMITER)\n",
    "        \n",
    "        interaction = {\n",
    "          \"journal\": line[0], # no change\n",
    "          \"article_id\": line[1], # no change\n",
    "          \"pubmed_id\": line[2], # no change\n",
    "          \"sentence_id\": line[3], # no change\n",
    "          \"mention1_offset\": line[4], # new data describes a mention1_offset_start and mention1_offset_end -- I arbitarily chose to just assign offset_start here (offset start and end are often the same anyway) \n",
    "          \"mention2_offset\": line[6], # same principle as above, but for mention2\n",
    "          \"mention1\": line[8], # no change\n",
    "          \"mention2\": line[9], # no change\n",
    "          \"geneids1\": line[10], # there's a column named \"geneids\", but it never seems to contain more than one value \"MESH:xxxxxxx\"\n",
    "          \"geneids2\": line[11], # the column after \"geneids\" is called \"disease_ids\", and may be a suitable substitute for this geneids value\n",
    "          \"probability\": line[12], # no change\n",
    "          \"excerpt\": line[1] # no excerpts provided, substituted with article name    \n",
    "        }\n",
    "        \n",
    "        interactions.append(interaction)\n",
    "print(interactions[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any interactions for which the a gene traces to multiple IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [i for i in interactions if ( ';' not in i['geneids1'] and ';' not in i['geneids2'])]\n",
    "interactions = [i for i in interactions if ('NULL' not in i['article_id'] and 'NULL' not in i['pubmed_id'] and 'NULL' not in i['sentence_id'] and 'NULL' not in i['mention1_offset'] and 'NULL' not in i['mention2_offset'] and 'NULL' not in i['mention1'] and 'NULL' not in i['mention2'] and 'NULL' not in i['geneids1'] and 'NULL' not in i['geneids2'] and 'NULL' not in i['probability'] and 'NULL' not in i['excerpt'])] #there's probably a shorter way of doing this, but I think this works for now -- excludes JOURNAL entries of course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeneDive expects the target genes in the excerpt to be wrapped in pound signs. This is important because a sentence may mention the target gene multiple times, so we need to use the offset data her to make sure we tag the right mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in interactions:\n",
    "#     #try:\n",
    "#     print(i)\n",
    "#     if (i['journal'] != 'journal'):\n",
    "#         excerpt = i['excerpt']\n",
    "    \n",
    "#         excerpt = re.sub('\"', '', excerpt)\n",
    "#         tokens = excerpt.split(\" \")\n",
    "#         offset1 = int(i['mention1_offset'])\n",
    "#         offset2 = int(i['mention2_offset'])\n",
    "        \n",
    "#         tokens[offset1] = \"\".join([\"#\",tokens[offset1],\"#\"])\n",
    "#         tokens[offset2] = \"\".join([\"#\",tokens[offset2],\"#\"])\n",
    "        \n",
    "#         i['excerpt'] = \" \".join(tokens)\n",
    "#     #except Exception:\n",
    "#     #    print(i[\"article_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specific for PMC Data**\n",
    "\n",
    "We didn't get Journal Data - we need to extract it from the article titles. Comment out the next section if journal titles were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in interactions:\n",
    "    journal = i['article_id'].split(\"_\")\n",
    "    x = 0\n",
    "\n",
    "    while x < len(journal):\n",
    "        if journal[x][:2] == \"19\" or journal[x][:2] == \"20\":\n",
    "            journal = \" \".join(journal[:x])\n",
    "            break\n",
    "            \n",
    "        x+= 1\n",
    "\n",
    "    i['journal'] = journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our insert statement - probably don't need to touch this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIONS_WRITE = '''insert into interactions ( journal, article_id, pubmed_id, sentence_id, mention1_offset, mention2_offset, mention1, mention2, geneids1, geneids2, probability, context, section, reactome ) values ( \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\" );'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: interactions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-6956b32f284d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mWRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: interactions"
     ]
    }
   ],
   "source": [
    "for interaction in interactions:\n",
    "    statement = INTERACTIONS_WRITE.format(\n",
    "        interaction['journal'],\n",
    "        interaction['article_id'],\n",
    "        interaction['pubmed_id'],\n",
    "        interaction['sentence_id'],\n",
    "        interaction['mention1_offset'],\n",
    "        interaction['mention2_offset'],\n",
    "        interaction['mention1'],\n",
    "        interaction['mention2'],\n",
    "        interaction['geneids1'],\n",
    "        interaction['geneids2'],\n",
    "        interaction['probability'],\n",
    "        interaction['excerpt'],\n",
    "        \"Unknown\",\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    cursor.execute(statement)\n",
    "\n",
    "if WRITE:\n",
    "    conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
