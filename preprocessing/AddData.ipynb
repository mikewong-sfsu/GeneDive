{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract-Transform-Load Script\n",
    "\n",
    "Extract-Transform-Load Scripts (ETLS) are common tools in data management. The purpose of ETLS is to gather relevant data (both direct and inferred) from public databases and capture important features in a possibly different data structure schema for specific analysis.\n",
    "\n",
    "## PubMed Central ETLS Example\n",
    "\n",
    "This script will Extract data from the CSV files provided to us by Stanford, Transform the data into a format usable by GeneDive, and then Load the data into the GeneDive sqlite database.\n",
    "\n",
    "Whenever new data is obtained for GeneDive, this process should be run against that dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress Bar I found on the internet.\n",
    "# https://github.com/alexanderkuk/log-progress\n",
    "from progress_bar import log_progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">IMPORTANT!</span> You need to create folders and organize the data before starting\n",
    "\n",
    "Below are many file names and directory names. You have to create the directories and put the files correctly in them.\n",
    "\n",
    "`GENE_GENE_INTERACTIONS_FILE`, `GENE_DRUG_INTERACTIONS_FILE`, and `GENE_DISEASE_INTERACTIONS_FILE` are TSV files from Emily. If they come with a .csv extension, and they are tab seperated, rename them. If they are deliminated some other way, change their extensions appropriately and change the value of `DELIMITER` below.\n",
    "\n",
    "`GOOD_PHARM_GKB_DB`, `GOOD_ALL_DB`, and `GOOD_PLOS_PMC_DB` are the current working, valid databases used in GeneDive. They will not be altered, but instead they will be copied and updated.\n",
    "\n",
    "`PLOS_PMC_DB` and `ALL_DB` are the newly generated databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOS_PMC_NAME = \"PLOS-PMC\"\n",
    "PHARMGKB_NAME = \"PHARMGKB\"\n",
    "ALL_NAME = \"ALL\"\n",
    "\n",
    "# TSV files containing PLOS-PMC data\n",
    "GENE_GENE_PLOS_INTERACTIONS_FILE    = 'tsv_data/plos_pmc/plos_with_excerpts.tsv'\n",
    "GENE_GENE_PMC_INTERACTIONS_FILE     = 'tsv_data/plos_pmc/pmc_with_excerpts.tsv'\n",
    "GENE_DRUG_INTERACTIONS_FILE         = 'tsv_data/genedrug_relationship_100417_sfsu_with_excerpts.tsv'\n",
    "GENE_DISEASE_INTERACTIONS_FILE      = 'tsv_data/genedisease_relationship_100417_sfsu_with_excerpts.tsv'\n",
    "\n",
    "# TSV files containing Pharm-GKB data\n",
    "PHARMGKB_INTERACTIONS_FILE          = 'tsv_data/pharmgkb/relationships.tsv'\n",
    "PHARMGKB_CHEMICAL_IDS_FILE          = 'tsv_data/pharmgkb/ids/chemicals.tsv'\n",
    "PHARMGKB_DRUGS_IDS_FILE             = 'tsv_data/pharmgkb/ids/drugs.tsv'\n",
    "PHARMGKB_GENES_IDS_FILE             = 'tsv_data/pharmgkb/ids/genes.tsv'\n",
    "PHARMGKB_PHENOTYPES_IDS_FILE        = 'tsv_data/pharmgkb/ids/phenotypes.tsv'\n",
    "\n",
    "# These will be unaltered\n",
    "GOOD_PHARM_GKB_DB = 'sqlite_data/good_data/data.pgkb.sqlite'\n",
    "GOOD_ALL_DB = 'sqlite_data/good_data/data.all.sqlite'\n",
    "GOOD_PLOS_PMC_DB = 'sqlite_data/good_data/data.plos-pmc.sqlite'\n",
    "\n",
    "# These will be created/overwritten\n",
    "PLOS_PMC_DB = 'sqlite_data/data.plos-pmc.sqlite' # This will be just the data from emilies files\n",
    "ALL_DB = 'sqlite_data/data.all.sqlite' # This is a combination of emilies files and PharmGKB\n",
    "\n",
    "# if excepts alrady come wrapped with pound signs, set this to false\n",
    "WRAP_EXCERPTS = True\n",
    "\n",
    "DELIMITER = \"\\t\"\n",
    "EMILYS_FILES = [\n",
    "    {\"filename\":GENE_GENE_PLOS_INTERACTIONS_FILE,\"type\":\"GeneGene\", \"source\" : \"PLOS\"},\n",
    "    {\"filename\":GENE_GENE_PMC_INTERACTIONS_FILE,\"type\":\"GeneGene\", \"source\" : \"PMC\"},\n",
    "    {\"filename\":GENE_DRUG_INTERACTIONS_FILE,\"type\":\"GeneDrug\", \"source\" : \"Emily\"},\n",
    "    {\"filename\":GENE_DISEASE_INTERACTIONS_FILE,\"type\":\"GeneDisease\", \"source\" : \"Emily\"},\n",
    "]\n",
    "\n",
    "PHARMGKB_ID_FILES = [\n",
    "     {\"filename\":PHARMGKB_CHEMICAL_IDS_FILE, \"type\" : \"chemicals\"},\n",
    "     {\"filename\":PHARMGKB_DRUGS_IDS_FILE, \"type\" : \"drugs\"},\n",
    "    {\"filename\":PHARMGKB_GENES_IDS_FILE, \"type\" : \"genes\",},\n",
    "     {\"filename\":PHARMGKB_PHENOTYPES_IDS_FILE, \"type\" : \"phenotypes\"},\n",
    "]\n",
    "\n",
    "\n",
    "MESH_VALUE = \"mesh\"\n",
    "PHARMGKB_VALUE = \"pgkb\"\n",
    "NCBI_VALUE = \"ncbi\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If write is false, the script will run but not write anything to the database. This keeps it safe while you're nosing around, and can also be useful if you need to re-generate the complete typeahead/adjacency files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This copies the fields, then initializes the connections. The `databases` array will be looped through at the end, applying all the interactions to each database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2(GOOD_PLOS_PMC_DB, PLOS_PMC_DB)\n",
    "conn_plos_pmc = sqlite3.connect(PLOS_PMC_DB)\n",
    "cursor_plos_pmc = conn_plos_pmc.cursor()\n",
    "\n",
    "copy2(GOOD_ALL_DB, ALL_DB)\n",
    "conn_all = sqlite3.connect(ALL_DB)\n",
    "cursor_all = conn_all.cursor()\n",
    "\n",
    "\n",
    "databases = [\n",
    "#     {\"conn\": conn_plos_pmc, \"cursor\": cursor_plos_pmc, \"name\": PLOS_PMC_NAME}, \n",
    "    {\"conn\": conn_all, \"cursor\": cursor_all, \"name\": ALL_NAME}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PharmGKB ids\n",
    "This data is used to convert ids in our database. Genes should be NCBI ids, Drugs should be PharmGKB, and Diseases should be Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PharmGKB Accession Id': 0, 'Name': 1, 'Generic Names': 2, 'Trade Names': 3, 'Brand Mixtures': 4, 'Type': 5, 'Cross-references': 6, 'SMILES': 7, 'InChI': 8, 'Dosing Guideline': 9, 'External Vocabulary': 10, 'Clinical Annotation Count': 11, 'Variant Annotation Count': 12, 'Pathway Count': 13, 'VIP Count': 14, 'Dosing Guideline Sources': 15, 'Top Clinical Annotation Level': 16, 'Top FDA Label Testing Level': 17, 'Top Any Drug Label Testing Level': 18, 'Label Has Dosing Info': 19, 'Has Rx Annotation': 20}\n",
      "{'PharmGKB Accession Id': 0, 'Name': 1, 'Generic Names': 2, 'Trade Names': 3, 'Brand Mixtures': 4, 'Type': 5, 'Cross-references': 6, 'SMILES': 7, 'InChI': 8, 'Dosing Guideline': 9, 'External Vocabulary': 10, 'Clinical Annotation Count': 11, 'Variant Annotation Count': 12, 'Pathway Count': 13, 'VIP Count': 14, 'Dosing Guideline Sources': 15, 'Top Clinical Annotation Level': 16, 'Top FDA Label Testing Level': 17, 'Top Any Drug Label Testing Level': 18, 'Label Has Dosing Info': 19, 'Has Rx Annotation': 20}\n",
      "{'PharmGKB Accession Id': 0, 'NCBI Gene ID': 1, 'HGNC ID': 2, 'Ensembl Id': 3, 'Name': 4, 'Symbol': 5, 'Alternate Names': 6, 'Alternate Symbols': 7, 'Is VIP': 8, 'Has Variant Annotation': 9, 'Cross-references': 10, 'Has CPIC Dosing Guideline': 11, 'Chromosome': 12, 'Chromosomal Start - GRCh37.p13': 13, 'Chromosomal Stop - GRCh37.p13': 14, 'Chromosomal Start - GRCh38.p7': 15, 'Chromosomal Stop - GRCh38.p7': 16}\n",
      "{'PharmGKB Accession Id': 0, 'Name': 1, 'Alternate Names': 2, 'Cross-references': 3, 'External Vocabulary': 4}\n"
     ]
    }
   ],
   "source": [
    "id_map = {}\n",
    "\n",
    "for id_file in PHARMGKB_ID_FILES:\n",
    "    with open(id_file[\"filename\"]) as file:\n",
    "        try:\n",
    "            header = None\n",
    "            linenum = 0\n",
    "            for line in file:\n",
    "                linenum+=1\n",
    "                pgkb = None\n",
    "                ncbi = None\n",
    "                mesh = None\n",
    "\n",
    "                # deliminate the lines\n",
    "                line = line.strip().split(DELIMITER)\n",
    "\n",
    "                # Read the headers of the file and assign them to a dictionary {column_name: column_number}\n",
    "                if linenum == 1:\n",
    "                    header = {name.strip(): col for col, name in enumerate(line)}\n",
    "                    print(header)                    \n",
    "                    continue\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                # set variables\n",
    "                pgkb = line[header[\"PharmGKB Accession Id\"]]\n",
    "\n",
    "                if \"NCBI Gene ID\" in header:\n",
    "                    ncbi = line[header[\"NCBI Gene ID\"]]\n",
    "                if 'External Vocabulary'in header:\n",
    "                    if len(line) > header['External Vocabulary']: # If a line doesn't have data on the end, it wont be in the delimination\n",
    "                        external = str(line[header['External Vocabulary']]).replace('\"', \"\") # weird bug where quotes break regex\n",
    "                        match = re.match('MESH:[0-9A-Za-z]+',external,re.IGNORECASE)\n",
    "                        if match != None:\n",
    "                            mesh = match.group(0).upper()\n",
    "\n",
    "                # fill map   \n",
    "                values = {PHARMGKB_VALUE: pgkb}                \n",
    "                if ncbi is not None:\n",
    "                    values[NCBI_VALUE] = ncbi\n",
    "                if mesh is not None:\n",
    "                    values[MESH_VALUE] = mesh\n",
    "        \n",
    "                id_map[pgkb] = values\n",
    "                \n",
    "                if ncbi is not None:\n",
    "                    id_map[ncbi] = values\n",
    "                if mesh is not None:\n",
    "                    id_map[mesh] = values\n",
    "                \n",
    "\n",
    "        except Exception as e:\n",
    "            print(line)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pgkb': 'PA447298', 'mesh': 'MESH:D054556'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to test\n",
    "id_map['PA447298']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOS-PMC\n",
    "Map the columns as they appear in the file to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the exercept is not found, don't run the Excerpt wrapping cell below\n",
    "excerptFound = False\n",
    "interactions = {\n",
    "    PLOS_PMC_NAME : [],\n",
    "    PHARMGKB_NAME : [],\n",
    "}\n",
    "for data_file in EMILYS_FILES:\n",
    "    \n",
    "    gene_drug_file = data_file[\"type\"] == \"GeneDrug\"\n",
    "    gene_disease_file = data_file[\"type\"] == \"GeneDisease\"\n",
    "    gene_gene_file = data_file[\"type\"] == \"GeneGene\"\n",
    "    \n",
    "    # Identifying each DGR based on the file type a Drug (r) / Chemical (c), Disease (d), or Gene (g),\n",
    "    dgd_type1 = \"\"\n",
    "    dgd_type2 = \"g\"\n",
    "    if gene_drug_file:\n",
    "        dgd_type1 = \"r\"\n",
    "    elif gene_disease_file:\n",
    "        dgd_type1 = \"d\"\n",
    "    elif gene_gene_file:\n",
    "        dgd_type1 = \"g\"\n",
    "    else:\n",
    "        raise ValueError('{type} is an unrecognized type in EMILYS_FILES'.format(type = data_file[\"type\"]))\n",
    "        \n",
    "    with open(data_file[\"filename\"], encoding='utf-8') as file :\n",
    "        header = None\n",
    "        linenum = 0  \n",
    "        for line in file:\n",
    "            linenum+=1\n",
    "            \n",
    "            # Read the headers of the file and assign them to a dictionary {column_name: column_number}\n",
    "            if linenum == 1:\n",
    "                header = {name.strip(): col for col, name in enumerate(line.split(DELIMITER))}\n",
    "                \n",
    "                # The GeneGene headers differ from Gene Drug and Gene Disease. This normalizes them.\n",
    "                if \"geneids\" in header and \"disease_ids\" in header: # GeneDrug/GeneDisease\n",
    "                    header[\"dgr1\"] = header[\"geneids\"]\n",
    "                    header[\"dgr2\"] = header[\"disease_ids\"]                    \n",
    "                    header[\"mention1_offset\"] = header[\"mention1_offset_start\"]\n",
    "                    header[\"mention2_offset\"] = header[\"mention2_offset_start\"]\n",
    "                elif \"geneids1\" in header and \"geneids2\" in header: # GeneGene\n",
    "                    header[\"dgr1\"] = header[\"geneids1\"]\n",
    "                    header[\"dgr2\"] = header[\"geneids2\"]\n",
    "                else:\n",
    "                    raise ValueError('{f} column headers didn\\'t contain expected values'.format(f = data_file[\"filename\"]))\n",
    "                \n",
    "                # if no excerpts provided, substituted with article name\n",
    "                needsTokens = False\n",
    "                if \"excerpt\" in header:                    \n",
    "                    excerptFound =  True\n",
    "                elif \"sentence\" in header:                    \n",
    "                    excerptFound =  True\n",
    "                    header[\"excerpt\"] = header[\"sentence\"]\n",
    "                else:\n",
    "                    header[\"excerpt\"] = header[\"article_id\"]\n",
    "                \n",
    "                continue\n",
    "                \n",
    "            line = line.strip().split(DELIMITER)\n",
    "            \n",
    "            section = \"Unknown\"\n",
    "            if \"section\" in data_file:\n",
    "                section = data_file[\"section\"]            \n",
    "            \n",
    "            interaction = {\n",
    "                \"journal\": line[header[\"journal\"]], # no change\n",
    "                \"article_id\": line[header[\"article_id\"]], # no change\n",
    "                \"pubmed_id\": (line[header[\"pubmed_id\"]],), # make it a tuple, so that it can be looped over later\n",
    "                \"sentence_id\": line[header[\"sentence_id\"]], # no change\n",
    "                \"mention1_offset\": line[header[\"mention1_offset\"]], # new data describes a mention1_offset_start and mention1_offset_end -- I arbitarily chose to just assign offset_start here (offset start and end are often the same anyway) \n",
    "                \"mention2_offset\": line[header[\"mention2_offset\"]], # same principle as above, but for mention2\n",
    "                \"mention1\": line[header[\"mention1\"]], # no change\n",
    "                \"mention2\": line[header[\"mention2\"]], # no change\n",
    "                \"geneids1\": line[header[\"dgr1\"]], # there's a column named \"geneids\", but it never seems to contain more than one value \"MESH:xxxxxxx\"\n",
    "                \"geneids2\": line[header[\"dgr2\"]], # the column after \"geneids\" is called \"disease_ids\", and may be a suitable substitute for this geneids value\n",
    "                \"confidence\": line[header[\"probability\"]], # no change\n",
    "                \"excerpt\": line[header[\"excerpt\"]],\n",
    "                \"type1\" : dgd_type1,\n",
    "                \"type2\" : dgd_type2,\n",
    "              }\n",
    "            \n",
    "            if data_file[\"source\"] == \"PMC\" and interaction[\"journal\"] == \"NULL\":\n",
    "                interaction[\"journal\"] = data_file[\"source\"]\n",
    "            \n",
    "            try:\n",
    "                mention1_offset = int(interaction[\"mention1_offset\"])\n",
    "                mention2_offset = int(interaction[\"mention2_offset\"])\n",
    "                excerpt = line[header[\"excerpt\"]]                \n",
    "            except Exception as e:\n",
    "                print(line)\n",
    "                print(mention1_offset,excerpt)\n",
    "                raise e\n",
    "    \n",
    "            interactions[PLOS_PMC_NAME].append(interaction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PharmGKB\n",
    "Map the columns as they appear in the file to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762d1bf07d7d4851a87e6a1185908ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=1, bar_style='info', max=1)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66690 interactions processed\n",
      "3754 didn't have Pubmed IDs\n",
      "20747 interactions were ignored due to having at least one of these types: {'Variant', 'VariantLocation'}\n"
     ]
    }
   ],
   "source": [
    "interactions[PHARMGKB_NAME] = []\n",
    "unmapped = {}\n",
    "\n",
    "def addToUnmapped(dgr, dgr_type_original, dgr_type_target):\n",
    "    unmapped[dgr] = \"{o} -/-> {t}\".format(o = dgr_type_original, t = dgr_type_target)\n",
    "    \n",
    "geneid_type = {\n",
    "    \"Gene\" : \"g\",\n",
    "    \"Disease\" : \"d\",\n",
    "    \"Chemical\" : \"c\",\n",
    "    \"Drug\" : \"r\",\n",
    "    \"Haplotype\" : \"d\",\n",
    "    # \"Variant\" : \"d\",\n",
    "    #\"VariantLocation\" : \"C\",\n",
    "    \n",
    "}\n",
    "\n",
    "types = set()\n",
    "\n",
    "# If not in the prepend dictionary, the type will not be added and instead added to this set\n",
    "types_ignored = set()\n",
    "total_ignored = 0\n",
    "\n",
    "# This prevents duplicates\n",
    "seen_interactions = set()\n",
    "duplicates_found = 0\n",
    "\n",
    "linenum = 0  \n",
    "no_pubmed_ids = 0\n",
    "# Prepending to identify each DGR so that they can be identified as a Gene (no-prepend), Drug (C), or Disease (D)\n",
    "with open(PHARMGKB_INTERACTIONS_FILE) as file:\n",
    "    header = None\n",
    "\n",
    "    for line in log_progress(file, every=1000, name=PHARMGKB_INTERACTIONS_FILE+\" progress\"):\n",
    "        linenum+=1\n",
    "        line = line.strip().split(DELIMITER)\n",
    "        \n",
    "        # Read the headers of the file and assign them to a dictionary {column_name: column_number}\n",
    "        if linenum == 1:\n",
    "            header = {name.strip(): col for col, name in enumerate(line)}\n",
    "            continue\n",
    "       \n",
    "        dgr1 = line[header[\"Entity1_id\"]]\n",
    "        dgr2 = line[header[\"Entity2_id\"]]\n",
    "        \n",
    "        # prepend the GeneIDs appropriately\n",
    "        try:\n",
    "            type1 = line[header[\"Entity1_type\"]]\n",
    "            dgr_type1 = geneid_type[type1]\n",
    "            if type1 not in types:\n",
    "                types.add(type1)\n",
    "        except KeyError:\n",
    "            types_ignored.add(type1)\n",
    "            total_ignored += 1\n",
    "            continue\n",
    "        try:\n",
    "            type2 = line[header[\"Entity2_type\"]]\n",
    "            dgr_type2 = geneid_type[type2]\n",
    "            if type2 not in types:\n",
    "                types.add(type2)\n",
    "        except KeyError:\n",
    "            types_ignored.add(type2)\n",
    "            total_ignored += 1\n",
    "            continue            \n",
    "\n",
    "        # Replace PharmGKB GeneIDs with NCBI ids\n",
    "        if dgr_type1 == \"g\":\n",
    "            if dgr1 not in id_map or NCBI_VALUE not in id_map[dgr1]:\n",
    "                addToUnmapped(dgr1, type1, NCBI_VALUE)\n",
    "            else:\n",
    "                dgr1 = id_map[dgr1][NCBI_VALUE]\n",
    "        if dgr_type2 == \"g\":\n",
    "            if dgr2 not in id_map or NCBI_VALUE not in id_map[dgr2]:\n",
    "                addToUnmapped(dgr2, type2, NCBI_VALUE)\n",
    "            else:\n",
    "                dgr2 = id_map[dgr2][NCBI_VALUE]\n",
    "            \n",
    "\n",
    "        if str(dgr_type1) not in \"dgrc\" or str(dgr_type2) not in \"dgrc\":\n",
    "            print(\"type1:\\\"{a}\\\", type2:\\\"{b}\\\"\".format(a = dgr_type1, b= dgr_type2))\n",
    "            raise ValueError(i)\n",
    "            \n",
    "        interaction = {\n",
    "            \"journal\": \"PubMed\", \n",
    "            \"article_id\": \"0\",\n",
    "            \"pubmed_id\": \"0\",\n",
    "            \"sentence_id\": \"0\", \n",
    "            \"mention1_offset\": \"0\", \n",
    "            \"mention2_offset\": \"0\",\n",
    "            \"mention1\": line[header[\"Entity1_name\"]],\n",
    "            \"mention2\": line[header[\"Entity2_name\"]],\n",
    "            \"geneids1\": dgr1,\n",
    "            \"geneids2\": dgr2,\n",
    "            \"confidence\": \"0.999\",\n",
    "            \"excerpt\": \"Source: PharmGKB\",\n",
    "            \"type1\" : dgr_type1,\n",
    "            \"type2\" : dgr_type2,\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # Not all lines will have PMIDs, and will error out if you try to access it\n",
    "        try:\n",
    "            pubids = line[header[\"PMIDs\"]].split(\";\")                \n",
    "            interaction[\"pubmed_id\"] = tuple(pubids)\n",
    "        except IndexError:\n",
    "            no_pubmed_ids += 1\n",
    "            continue\n",
    "            \n",
    "                    \n",
    "        # Remap Diseases to MESH\n",
    "        if dgr_type1 == \"d\":\n",
    "            if dgr1 not in id_map or MESH_VALUE not in id_map[dgr1]:\n",
    "                addToUnmapped(dgr1, type1, MESH_VALUE)\n",
    "            else:\n",
    "                dgr1 = id_map[dgr1][MESH_VALUE]\n",
    "        if dgr_type2 == \"d\":\n",
    "            if dgr2 not in id_map or MESH_VALUE not in id_map[dgr2]:\n",
    "                addToUnmapped(dgr2, type2, MESH_VALUE)\n",
    "            else:\n",
    "                dgr2 = id_map[dgr2][MESH_VALUE]\n",
    "                \n",
    "               \n",
    "        interactions[PHARMGKB_NAME].append(interaction)\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "print(\"{total} interactions processed\".format(total = linenum))\n",
    "print(\"{missing} didn't have Pubmed IDs\".format(missing = no_pubmed_ids))\n",
    "print(\"{ignore} interactions were ignored due to having at least one of these types:\".format(ignore=total_ignored), types_ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pgkb': 'PA166114942'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map[\"PA166114942\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any interactions for which the a gene traces to multiple IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLOS-PMC:\n",
      "    Total Interactions:     3832749\n",
      "    Filtered Interactions:  703112\n",
      "    Remaining Interactions: 3129637\n",
      "PHARMGKB:\n",
      "    Total Interactions:     42188\n",
      "    Filtered Interactions:  4\n",
      "    Remaining Interactions: 42184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def invalidInteraction(i):\n",
    "    t1 = i['type1']\n",
    "    t2 = i['type2']\n",
    "    id1 = i['geneids1']\n",
    "    id2 = i['geneids2']\n",
    "    \n",
    "    if t1 not in \"dgrc\" or t2 not in \"dgrc\":\n",
    "        print(\"type1:\\\"{a}\\\", type2:\\\"{b}\\\"\".format(a = t1, b= t2))\n",
    "        raise ValueError(i)\n",
    "        \n",
    "    if (\"PA\" in id1 and \"g\" == t1) or (\"PA\" in id2 and \"g\" == t2):\n",
    "        raise ValueError(i)\n",
    "    \n",
    "    return (';' in i['geneids1'] \n",
    "    or ';'    in i['geneids2']\n",
    "    or 'NULL' in i['article_id'] \n",
    "    or 'NULL' in i['pubmed_id'] \n",
    "    or 'NULL' in i['sentence_id'] \n",
    "    or 'NULL' in i['mention1_offset'] \n",
    "    or 'NULL' in i['mention2_offset'] \n",
    "    or 'NULL' in i['mention1'] \n",
    "    or 'NULL' in i['mention2'] \n",
    "    or 'NULL' in i['geneids1'] or len(i['geneids1']) == 0\n",
    "    or 'NULL' in i['geneids2'] or len(i['geneids2']) == 0\n",
    "    or 'NULL' in i['confidence'] \n",
    "    or 'NULL' in i['excerpt'])\n",
    "       \n",
    "for source in interactions:\n",
    "    totalInteractions = len(interactions[source])\n",
    "\n",
    "    interactions[source] = [x for x in interactions[source] if not invalidInteraction(x)]\n",
    "\n",
    "    newTotal = len(interactions[source])\n",
    "    print(\n",
    "    '''{source}:\n",
    "    Total Interactions:     {total}\n",
    "    Filtered Interactions:  {filtered}\n",
    "    Remaining Interactions: {remaining}'''\n",
    "          .format(source = source, total = totalInteractions,filtered=totalInteractions-newTotal , remaining =newTotal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excerpt wrapping\n",
    "GeneDive expects the target genes in the excerpt to be wrapped in pound signs. This is important because a sentence may mention the target gene multiple times, so we need to use the offset data her to make sure we tag the right mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total skipped 1839635\n"
     ]
    }
   ],
   "source": [
    "total_skipped = 0\n",
    "if excerptFound and WRAP_EXCERPTS:\n",
    "    for i in interactions[PLOS_PMC_NAME]:\n",
    "        #try:\n",
    "        if i['journal'] != 'journal' and 'excerpt' in i:\n",
    "            excerpt = i['excerpt']\n",
    "\n",
    "            excerpt = re.sub('\"', '', excerpt)\n",
    "            tokens = excerpt.split(\" \")\n",
    "            offset1 = int(i['mention1_offset'])\n",
    "            offset2 = int(i['mention2_offset'])\n",
    "            \n",
    "\n",
    "            \n",
    "            if ( offset1 >= len(tokens) or offset2 >= len(tokens) ) or ('#'+i['mention1']+'#' in excerpt or '#'+i['mention2']+'#' in excerpt):\n",
    "                total_skipped+=1\n",
    "                continue\n",
    "\n",
    "            tokens[offset1] = \"\".join([\"#\",tokens[offset1],\"#\"])\n",
    "            tokens[offset2] = \"\".join([\"#\",tokens[offset2],\"#\"])\n",
    "\n",
    "            i['excerpt'] = \" \".join(tokens)\n",
    "        #except Exception:\n",
    "        #    print(i[\"article_id\"])\n",
    "print(\"Total skipped \" + str(total_skipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specific for PMC Data**\n",
    "\n",
    "We didn't get Journal Data - we need to extract it from the article titles. Comment out the next section if journal titles were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in interactions[PLOS_PMC_NAME]:\n",
    "    journal_split = i['article_id'].split(\"_\")\n",
    "    x = 0\n",
    "    length = len(journal_split)\n",
    "    journal = \"\"\n",
    "    \n",
    "    while x < length:\n",
    "        if journal_split[x][:2] == \"19\" or journal_split[x][:2] == \"20\" or x == length -1:\n",
    "            journal = \" \".join(journal_split[:x])\n",
    "            break\n",
    "        x+= 1\n",
    "    \n",
    "    break\n",
    "\n",
    "    i['journal'] = journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our insert statement - probably don't need to touch this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIONS_WRITE = '''insert into interactions ( journal, article_id, pubmed_id, sentence_id, mention1_offset, mention2_offset, mention1, mention2, geneids1, geneids2, probability, context, section, reactome , type1, type2) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ,? ,?);'''\n",
    "DELETE_PHARMGKB_DATA = '''DELETE FROM interactions WHERE journal = \"PharmGKB\";'''\n",
    "DELETE_ALL = '''DELETE FROM interactions'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the data to sqlite files\n",
    "\n",
    "This will load the data into the plos-pmc database and the all database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ffd8ddda3d4786b1774fe8f41564c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=3171821)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All databases complete\n"
     ]
    }
   ],
   "source": [
    "# Sort the DGRs so that the lower alphanumeric mention is the first one\n",
    "def sort_interaction_dgrs(interaction):\n",
    "    \n",
    "    if interaction[\"mention1\"].lower() > interaction[\"mention2\"].lower():\n",
    "        # store temp\n",
    "        temp_mention1 = interaction[\"mention1\"]\n",
    "        temp_geneids1 = interaction[\"geneids1\"]\n",
    "        temp_type1 = interaction[\"type1\"]\n",
    "        temp_mention1_offset = interaction['mention1_offset']\n",
    "        \n",
    "        # move 2 to 1\n",
    "        interaction[\"mention1\"] = interaction[\"mention2\"]\n",
    "        interaction[\"geneids1\"] = interaction[\"geneids2\"]\n",
    "        interaction[\"type1\"] = interaction[\"type2\"]\n",
    "        interaction[\"mention1_offset\"] = interaction[\"mention2_offset\"]\n",
    "        \n",
    "        # move 1 to 2\n",
    "        interaction[\"mention2\"] = temp_mention1\n",
    "        interaction[\"geneids2\"] = temp_geneids1\n",
    "        interaction[\"type2\"] = temp_type1\n",
    "        interaction[\"mention2_offset\"] = temp_mention1_offset\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "current_interaction = 0\n",
    "for sql in databases:\n",
    "    try:\n",
    "        statement = tuple();\n",
    "        # Delete all data in interactions table\n",
    "        sql[\"cursor\"].execute(DELETE_ALL)\n",
    "        sql[\"conn\"].commit()\n",
    "        sql[\"cursor\"].execute(\"Select * from interactions\")\n",
    "        if sql[\"cursor\"].rowcount > 0:\n",
    "            raise ValueError(\"There is more rows than expected\" + sql[\"cursor\"].rowcount)\n",
    "        \n",
    "        # Select interactions based on which SQL we're generating\n",
    "        if sql[\"name\"] == PLOS_PMC_NAME:\n",
    "            cur_interactions = interactions[PLOS_PMC_NAME]\n",
    "        elif sql[\"name\"] == ALL_NAME:\n",
    "            cur_interactions = interactions[PHARMGKB_NAME] + interactions[PLOS_PMC_NAME]\n",
    "        else:\n",
    "            raise NameError(\"Could not find \"+sql[\"name\"])\n",
    "            \n",
    "        for interaction in log_progress(cur_interactions, every=10000, name=sql[\"name\"]+\" database progress\"):\n",
    "            current_interaction = interaction\n",
    "            \n",
    "            # If not a tuple, end it\n",
    "            if type(interaction['pubmed_id']) is not tuple:\n",
    "                raise TypeError(\"pubmed_id \"+interaction['pubmed_id']+ \"is not a tuple\")\n",
    "                \n",
    "            sort_interaction_dgrs(interaction)\n",
    "            dgr_type2=interaction['type1']\n",
    "            dgr_type1= interaction['type2']\n",
    "                \n",
    "            for pubid in interaction['pubmed_id']:\n",
    "                statement = (\n",
    "                    interaction['journal'],         # journal\n",
    "                    interaction['article_id'],      # article_id \n",
    "                    pubid,                          # pubmed_id\n",
    "                    interaction['sentence_id'],     # sentence_id\n",
    "                    interaction['mention1_offset'], # mention1_offset\n",
    "                    interaction['mention2_offset'], # mention2_offset\n",
    "                    interaction['mention1'],        # mention1\n",
    "                    interaction['mention2'],        # mention2\n",
    "                    interaction['geneids1'],        # geneids1\n",
    "                    interaction['geneids2'],        # geneids2\n",
    "                    interaction['confidence'],      # probability\n",
    "                    interaction['excerpt'],         # context\n",
    "                    \"Unknown\",         # section\n",
    "                    0,                              # reactome\n",
    "                    interaction['type1'],           # type1\n",
    "                    interaction['type2'],           # type2\n",
    "                )\n",
    "\n",
    "\n",
    "                sql[\"cursor\"].execute(INTERACTIONS_WRITE,statement)\n",
    "\n",
    "        if WRITE:\n",
    "            sql[\"conn\"].commit()\n",
    "    except Exception as e:\n",
    "        print(INTERACTIONS_WRITE, statement)\n",
    "        print(current_interaction)\n",
    "        print('pubmed_id:',interaction['pubmed_id'])\n",
    "        print(\"type of pubmed_id:\", type(interaction['pubmed_id']))        \n",
    "        raise e\n",
    "\n",
    "\n",
    "\n",
    "print(\"All databases complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql[\"conn\"].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
